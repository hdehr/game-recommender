{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76afa330-8e47-4458-a05a-30dd8b9d31b6",
   "metadata": {},
   "source": [
    "This project creates a neural matrix factorization model to recommend video games listed on the steam store.\n",
    "\n",
    "We train using user reviews on the steam store obtained from [https://www.kaggle.com/datasets/antonkozyriev/game-recommendations-on-steam](https://www.kaggle.com/datasets/antonkozyriev/game-recommendations-on-steam). The data is partitioned into train, validation, and test sets where the latter two consist only of users' most recent reviews which are also positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8abc25c-b640-4773-a8ef-5d895c4c8ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "\n",
    "def prepare_data():\n",
    "    # Process original data into convenient training, validation, and testing datasets.\n",
    "    recommendations = pd.read_csv(\"./data/original/recommendations.csv\", usecols=['user_id', 'app_id', 'is_recommended', 'date'])\n",
    "    recommendations = recommendations[['user_id', 'app_id', 'is_recommended', 'date']].sample(frac=1)\n",
    "    games = pd.read_csv(\"./data/original/games.csv\", usecols=['app_id', 'title'])\n",
    "    \n",
    "    # Pytorch embedding layers require inputs within a range, so we replace the provided\n",
    "    # user and game identifers with enumerations.\n",
    "    users_in_rec = sorted(recommendations.user_id.unique())\n",
    "    games_in_rec = sorted(recommendations.app_id.unique())\n",
    "    user_map = {user_id : index for index, user_id in enumerate(users_in_rec)}\n",
    "    game_map = {app_id : index for index, app_id in enumerate(games_in_rec)}\n",
    "    recommendations.user_id = recommendations.user_id.map(lambda x: user_map[x]).astype('int32')\n",
    "    recommendations.app_id = recommendations.app_id.map(lambda x: game_map[x]).astype('int32')\n",
    "    games['external_app_id'] = games['app_id']\n",
    "    games.app_id = games.app_id.map(lambda x: game_map[x] if x in game_map else len(games)).astype('int32')\n",
    "    games = games.sort_values('app_id')\n",
    "    games.app_id = range(len(games))\n",
    "    \n",
    "    # Hold out some users' most recent review for validation and testing, if positive.\n",
    "    test_recs = recommendations.loc[recommendations.groupby('user_id').date.idxmax()]\n",
    "    test_recs = test_recs.loc[test_recs.is_recommended].sample(n=10000)\n",
    "    train_recs = recommendations.loc[recommendations.index.difference(test_recs.index)]\n",
    "    train_recs = train_recs.drop(columns=['date'])\n",
    "    test_recs = test_recs.drop(columns=['date'])\n",
    "    train_recs['observed'] = True\n",
    "    \n",
    "    valid_recs = test_recs.sample(frac=0.5)\n",
    "    test_recs = test_recs.loc[test_recs.index.difference(valid_recs.index)]\n",
    "    valid_recs.to_csv(\"./data/prepared/valid_recs.csv\", index=False)\n",
    "    test_recs.to_csv(\"./data/prepared/test_recs.csv\", index=False)\n",
    "    train_recs.to_csv(\"./data/prepared/train_recs.csv\", index=False)\n",
    "    games.to_csv(\"./data/prepared/games.csv\", index=False)\n",
    "    with open(\"./data/prepared/misc.json\", 'w') as file:\n",
    "        json.dump({'num_users': len(users_in_rec), 'num_games': len(games_in_rec)}, file)\n",
    "\n",
    "prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74b8deb-961f-4a84-bf6a-3a63eaa59192",
   "metadata": {},
   "source": [
    "Next, load the prepared data into pytorch Dataset objects. The InteractionsDataset class is used for training. In addition to the observed data, it generates unobserved user-game interactions. A given game appears in an unobserved interaction with probability proportional to its occurences in the explicit data. Since most user reviews are positive, this sampling scheme prevents introducing a large bias towards games with many reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea6cffb-30ce-4324-b869-8fda91af114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "UNOBSERVED_RATIO = 4\n",
    "RANKING_LIST_SIZE = 100\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "\n",
    "def reduce_memory(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'int64':\n",
    "            df[col] = df[col].astype('int32')\n",
    "    return df\n",
    "\n",
    "class InteractionsDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for training. Contains recommendations and user-game pairs for which\n",
    "    there is no corresponding review.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, interactions, num_users, unobserved_ratio=UNOBSERVED_RATIO):\n",
    "        super().__init__()\n",
    "        self.data = interactions.set_index(['user_id', 'app_id'], drop=False).sort_index()\n",
    "        self.length = int(len(self.data) * (1+unobserved_ratio))\n",
    "        self.num_users = num_users\n",
    "        # This line gets around memory problems seemlingly related to https://github.com/pytorch/pytorch/issues/13246\n",
    "        (0, random.choice(self.data.app_id.to_numpy())) in self.data.index\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if key < len(self.data):\n",
    "            return torch.tensor(self.data.iloc[key].to_numpy(dtype='int32'))\n",
    "        rand_user = random.randrange(self.num_users)\n",
    "        rand_game = random.choice(self.data.app_id.to_numpy())\n",
    "        while (rand_user, rand_game) in self.data.index:\n",
    "            rand_user = random.randrange(self.num_users)\n",
    "            rand_game = random.choice(self.data.app_id.to_numpy())\n",
    "        return torch.tensor([rand_user, rand_game, 0, 0], dtype=torch.int32)\n",
    "\n",
    "class RankingDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for validation or testing. Yields a recommendation along with a \n",
    "    fixed number of unobserved user-game pairs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, interactions, num_games, size=RANKING_LIST_SIZE):\n",
    "        super().__init__()\n",
    "        self.data = interactions\n",
    "        self.num_games = num_games\n",
    "        self.list_size = size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        target = self.data.loc[key]\n",
    "        candidates = [[target.user_id, target.app_id]]\n",
    "        app_ids = set([target.app_id])\n",
    "        while len(candidates) < self.list_size:\n",
    "            game = random.randrange(num_games)\n",
    "            if game not in app_ids:\n",
    "                candidates.append([target.user_id, game])\n",
    "                app_ids.add(game)\n",
    "        return torch.tensor(candidates)\n",
    "\n",
    "num_users = 0\n",
    "num_games = 0\n",
    "with open(\"./data/prepared/misc.json\") as file:\n",
    "    data = json.load(file)\n",
    "    num_users = data['num_users']\n",
    "    num_games = data['num_games']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd34a1-abb0-4ac4-a8dc-e681af8ebdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Length of embedding vectors for the generalized matrix factorization and\n",
    "# multilayer perceptron components of the model.\n",
    "GMF_VECTOR_LENGTH = 16\n",
    "MLP_VECTOR_LENGTH = 16\n",
    "\n",
    "class NeuMF(nn.Module):\n",
    "    \"\"\"Computes a similarity score between user and game embedding vectors.\"\"\"\n",
    "    \n",
    "    def __init__(self, gmf_vector_length=GMF_VECTOR_LENGTH, mlp_vector_length=MLP_VECTOR_LENGTH):\n",
    "        super().__init__()\n",
    "        self.gmf_vector_length = gmf_vector_length\n",
    "        self.mlp_vector_length = mlp_vector_length\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2 * self.mlp_vector_length, self.mlp_vector_length),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(self.mlp_vector_length, int(self.mlp_vector_length / 2)),\n",
    "        )\n",
    "        self.activation = nn.SiLU()\n",
    "        self.predict = nn.Linear(self.gmf_vector_length + int(self.mlp_vector_length / 2), 1)\n",
    "\n",
    "    def forward(self, user_embedding, game_embedding):\n",
    "        x = torch.cat((game_embedding[:, self.gmf_vector_length:], user_embedding[:, self.gmf_vector_length:]), 1)\n",
    "        x = self.mlp(x)\n",
    "        x = torch.cat((x, game_embedding[:, :self.gmf_vector_length] * user_embedding[:, :self.gmf_vector_length]), 1)\n",
    "        x = self.activation(x)\n",
    "        return self.predict(x).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35718d45-3645-47fb-9911-0024c3d1c639",
   "metadata": {},
   "source": [
    "The training loop uses binary cross entropy as the loss function. A positive recommendation is treated as the user liking the game with probability 1, and a negative recommendation as the user liking the game with probability 0. The probability score for an unobserved interaction is a tunable parameter, as is the weight these instances are given in the loss function.\n",
    "\n",
    "For validation and testing, a positive recommendation is evaluated along with a fixed number of unobserved interactions for the same user. The resulting ranking of user-game pairs is scored using the [Normalized Discounted Cumulative Gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af966df-6429-4eef-a36d-b17a30be68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "UNOBSERVED_WEIGHT = 1\n",
    "UNOBSERVED_SCORE = 0.05\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "def train_loop(dataloader, model, user_embedding, game_embedding):\n",
    "    # Train the neural matrix factorization and embedding models using a binary\n",
    "    # cross entropy loss function.\n",
    "    size = len(dataloader.dataset)\n",
    "    model_opt = torch.optim.AdamW(model.parameters())\n",
    "    user_opt = torch.optim.SparseAdam(user_embedding.parameters())\n",
    "    game_opt = torch.optim.SparseAdam(game_embedding.parameters())\n",
    "    model.train()\n",
    "    user_embedding.train()\n",
    "    game_embedding.train()\n",
    "    for batch, X in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        pred = model(user_embedding(X[:,0]), game_embedding(X[:,1]))\n",
    "        target = X[:,2] + torch.logical_not(X[:,3]) * UNOBSERVED_SCORE\n",
    "        weight = UNOBSERVED_WEIGHT + X[:, 3] * (1 - UNOBSERVED_WEIGHT)\n",
    "        loss = F.binary_cross_entropy_with_logits(pred, target, weight=weight)\n",
    "\n",
    "        loss.backward()\n",
    "        model_opt.step()\n",
    "        user_opt.step()\n",
    "        game_opt.step()\n",
    "        model_opt.zero_grad()\n",
    "        user_opt.zero_grad()\n",
    "        game_opt.zero_grad()\n",
    "\n",
    "        if batch % 100000 == 0:\n",
    "            loss = loss.item()\n",
    "            current = batch * BATCH_SIZE + len(X)\n",
    "            print(f\"Training Loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test_loop(dataloader, model, user_embedding, game_embedding, k=None):\n",
    "    # Calculate the average Normalized Cumulative Discounted Gain.\n",
    "    model.eval()\n",
    "    user_embedding.eval()\n",
    "    game_embedding.eval()\n",
    "    normalized_cumulative_discounted_gain = 0\n",
    "    with torch.no_grad():\n",
    "        for X in dataloader:\n",
    "            X = X.to(device)\n",
    "            score = model(user_embedding(X[:,0]), game_embedding(X[:,1]))\n",
    "            rank = (score >= score[0]).sum()\n",
    "            if k is None or rank <= k:\n",
    "                normalized_cumulative_discounted_gain += math.log(2) / torch.log(rank+1)\n",
    "    return normalized_cumulative_discounted_gain / len(dataloader)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f04ce-3173-4329-87f5-5729c346cb0c",
   "metadata": {},
   "source": [
    "Below, we train model until the validation score stops improving which seems to be after four epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2584050-c8fd-4494-a167-0ce118653e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuMF().to(device)\n",
    "user_embedding = nn.Embedding(num_users, GMF_VECTOR_LENGTH + MLP_VECTOR_LENGTH, sparse=True).to(device)\n",
    "game_embedding = nn.Embedding(num_games, GMF_VECTOR_LENGTH + MLP_VECTOR_LENGTH, sparse=True).to(device)\n",
    "\n",
    "valid_recs = reduce_memory(pd.read_csv(\"./data/prepared/valid_recs.csv\"))\n",
    "train_recs = reduce_memory(pd.read_csv(\"./data/prepared/train_recs.csv\"))\n",
    "train_dataset = InteractionsDataset(train_recs, num_users)\n",
    "validation_dataset = RankingDataset(valid_recs, num_games)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=RandomSampler(train_dataset), num_workers=16, pin_memory=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=None, pin_memory=True)\n",
    "\n",
    "accuracy = 0\n",
    "epoch = 0\n",
    "while True:\n",
    "    epoch += 1\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    train_loop(train_dataloader, model, user_embedding, game_embedding)\n",
    "    new_acc = test_loop(validation_dataloader, model, user_embedding, game_embedding)\n",
    "    print(f\"Average Validation Accuracy: {new_acc:>5f} \\n\")\n",
    "    if new_acc > accuracy:\n",
    "        accuracy = new_acc\n",
    "        torch.save(model.state_dict(), \"NeuMF_weights.pth\")\n",
    "        torch.save(user_embedding.state_dict(), \"user_embedding_weights.pth\")\n",
    "        torch.save(game_embedding.state_dict(), \"game_embedding_weights.pth\")\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e1c2ce-6504-46b5-bf14-78b5ce60bfcb",
   "metadata": {},
   "source": [
    "We can call the function below to get recommendations for a given user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a508a475-4ee1-4d7b-8f62-c0fa36a7829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuMF().to(device)\n",
    "user_embedding = nn.Embedding(num_users, GMF_VECTOR_LENGTH + MLP_VECTOR_LENGTH, sparse=True).to(device)\n",
    "game_embedding = nn.Embedding(num_games, GMF_VECTOR_LENGTH + MLP_VECTOR_LENGTH, sparse=True).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"NeuMF_weights.pth\"))\n",
    "user_embedding.load_state_dict(torch.load(\"user_embedding_weights.pth\"))\n",
    "game_embedding.load_state_dict(torch.load(\"game_embedding_weights.pth\"))\n",
    "\n",
    "games = reduce_memory(pd.read_csv(\"./data/prepared/games.csv\"))\n",
    "\n",
    "def recommend(user, model, user_embedding, game_embedding):\n",
    "    # Return collection of recommended games for user.\n",
    "    model.eval()\n",
    "    user_embedding.eval()\n",
    "    game_embedding.eval()\n",
    "    with torch.no_grad():\n",
    "        # Only evaluate games the user has not interacted with.\n",
    "        played_games = reduce_memory(pd.read_csv(\"./data/original/recommendations.csv\", usecols=['user_id', 'app_id']))\n",
    "        played_games = set(played_games.loc[played_games.user_id == user].app_id.to_numpy())\n",
    "        unplayed_games = games.iloc[:num_games]\n",
    "        unplayed_games = torch.tensor(unplayed_games.loc[~unplayed_games.external_app_id.isin(played_games)].app_id.to_numpy())\n",
    "        scores_list = []\n",
    "        u = user_embedding(torch.tensor([user], device=device))\n",
    "        i = 0\n",
    "        # Evaluate each unplayed game against the user.\n",
    "        while i < len(unplayed_games):\n",
    "            g = game_embedding(unplayed_games[i:i+256].to(device))\n",
    "            scores_list.append(model(u.expand(len(g), -1), g).cpu())\n",
    "            i += 256\n",
    "        ranking = torch.argsort(torch.cat(scores_list, dim=0), descending=True)\n",
    "        top = set(ranking[:20].tolist())\n",
    "        return games.loc[games.app_id.isin(top)].title.to_numpy()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4959eb68-4b3d-4077-94da-dd38462efbc2",
   "metadata": {},
   "source": [
    "Combine training and validation data for final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e25b52-1e95-48a4-8b72-ef619509235a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_recs = reduce_memory(pd.read_csv(\"./data/prepared/valid_recs.csv\"))\n",
    "train_recs = reduce_memory(pd.read_csv(\"./data/prepared/train_recs.csv\"))\n",
    "\n",
    "valid_recs['observed'] = True\n",
    "train_dataset = InteractionsDataset(pd.concat([train_recs, valid_recs]), num_users)\n",
    "\n",
    "model = NeuMF().to(device)\n",
    "user_embedding = nn.Embedding(num_users, GMF_VECTOR_LENGTH + MLP_VECTOR_LENGTH, sparse=True).to(device)\n",
    "game_embedding = nn.Embedding(num_games, GMF_VECTOR_LENGTH + MLP_VECTOR_LENGTH, sparse=True).to(device)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=RandomSampler(train_dataset), num_workers=16, pin_memory=True)\n",
    "for epoch in range(1, 5):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    train_loop(train_dataloader, model, user_embedding, game_embedding)\n",
    "    torch.save(model.state_dict(), \"NeuMF_weights.pth\")\n",
    "    torch.save(user_embedding.state_dict(), \"user_embedding_weights.pth\")\n",
    "    torch.save(game_embedding.state_dict(), \"game_embedding_weights.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff18b7bc-7a83-4d8a-8efe-47c77b1ede00",
   "metadata": {},
   "source": [
    "Evaluating the model on the test set, we get a score of 0.4324, up from the score of approximately 0.2 that a newly initialized model yields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab77298-2a3b-425f-8b58-03872ef0e20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuMF().to(device)\n",
    "user_embedding = nn.Embedding(num_users, GMF_VECTOR_LENGTH + MLP_VECTOR_LENGTH, sparse=True).to(device)\n",
    "game_embedding = nn.Embedding(num_games, GMF_VECTOR_LENGTH + MLP_VECTOR_LENGTH, sparse=True).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"NeuMF_weights.pth\"))\n",
    "user_embedding.load_state_dict(torch.load(\"user_embedding_weights.pth\"))\n",
    "game_embedding.load_state_dict(torch.load(\"game_embedding_weights.pth\"))\n",
    "\n",
    "test_recs = reduce_memory(pd.read_csv(\"./data/prepared/valid_recs.csv\"))\n",
    "test_dataset = RankingDataset(test_recs, num_games)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=None, pin_memory=True)\n",
    "print(test_loop(test_dataloader, model, user_embedding, game_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0f675a-cc0c-4a16-ac60-6de6f89b0605",
   "metadata": {},
   "source": [
    "## References\n",
    "1. [Neural Collaborative Filtering Paper](https://arxiv.org/abs/1708.05031)\n",
    "2. [Steam Recommendation Dataset](https://www.kaggle.com/datasets/antonkozyriev/game-recommendations-on-steam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8ced4d-3786-4542-9597-568c3ebc88a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
